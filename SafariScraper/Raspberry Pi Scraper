import requests
from glob import glob
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
from time import sleep


# USER AGENT FOR SAFARI 16
HEADERS = ({'User-Agent': 
            'Mozilla/5.0 (Macintosh Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Safari/605.1.15',
            'Accept Language' : 'en-US, en;q=0.5'})


# IMPORT CSV FILE FOR TRACKER
prod_tracker = pd.read_csv ('/Users/keithapplegate/Documents/GitHub/donutrescue/SafariScraper/tracker/Product_Tracker.csv', sep=';')
prod_tracker_URLS = prod_tracker.url

#Request Urls
page = requests.get(prod_tracker_URLS[0], headers=HEADERS)

# create the object that will contain all the info in the url
soup = BeautifulSoup(page.content, features="lxml")

title = soup.find(id='product-title').get_text().strip()

# to prevent script from crashing when there isn't a price for the product
try:
    price = float(soup.find(id='priceblock_ourprice').get_text().replace('.', '').replace('â‚¬', '').replace(',', '.').strip())
except:
    price = ''

# review score
review_score = float(soup.select('.a-star-4-5')[0].get_text().split(' ')[0].replace(",", "."))

# how many reviews
review_count = int(soup.select('#acrCustomerReviewText')[0].get_text().split(' ')[0].replace(".", ""))

# checking if there is "Out of stock" and if not, it means the product is available
try:
    soup.select('#availability .a-color-state')[0].get_text().strip()
    stock = 'Out of Stock'
except:
    stock = 'Available'

log = pd.DataFrame({'date': now.replace('h',':').replace('m',''),
    'code': prod_tracker.code[x], # this code comes from the TRACKER_PRODUCTS file
    'url': url,
    'title': title,
    'buy_below': prod_tracker.buy_below[x], # this price comes from the TRACKER_PRODUCTS file
    'price': price,
    'stock': stock,
    'review_score': review_score,
    'review_count': review_count}, index=[x])

try:
    # This is where you can integrate an email alert!
    if price < prod_tracker.buy_below[x]:
        print('************************ ALERT! Buy the '+prod_tracker.code[x]+' ************************')
            
except:
    # sometimes we don't get any price, so there will be an error in the if condition above
    pass

tracker_log = tracker_log.append(log)
print('appended '+ prod_tracker.code[x] +'\n' + title + '\n\n')            
sleep(5)
        
nterval += 1# counter update
        
sleep(interval_hours*1*1)
print('end of interval '+ str(interval))
    
# after the run, checks last search history record, and appends this run results to it, saving a new file
last_search = glob('[REPLACE WITH YOUR OWN PATH -> C:/Amazon Webscraper/search_history/*.xlsx')[-1] # path to file in the folder
search_hist = pd.read_excel(last_search)
final_df = search_hist.append(tracker_log, sort=False)
    
final_df.to_excel('search_history/SEARCH_HISTORY_{}.xlsx'.format(now), index=False)
print('end of search')